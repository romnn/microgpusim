#
# General configuration
#
config:
  results_dir: ../results
  materialize_to: ./test-apps-materialized.yml
  trace:
    full_trace: true
    save_json: false
    # one benchmark at once to not stress the GPU
    concurrency: 1
    # tracing does not require multiple repetitions
    repetitions: 1
    # skip certain kernels used for cache invalidation
    skip_kernel_prefixes:
      - gpucachesim_skip
  accelsim_trace:
    # one benchmark at once to not stress the GPU
    concurrency: 1
    # tracing does not require multiple repetitions
    repetitions: 1
  profile:
    # one benchmark at once to not stress the GPU
    concurrency: 1
    # profiling has very high statistical error
    # also, we use repetitions to warm up the GPU
    repetitions: 10
    keep_log_file: true
  # for simulation, we do not set a limit on concurrency
  simulate:
    # No concurrency limit for now (until we implement multi-threading)
    concurrency: 4 # null
    repetitions: 1
    # this is added to all inputs
    inputs:
      mode: ["serial", "deterministic", "nondeterministic"]
      threads: [4, 8]
      run_ahead: [5, 10]
      cores_per_cluster: [1, 4, 8]
      memory_only: [false, true]
      exclude:
        - mode: serial
          threads: 8
        - mode: serial
          run_ahead: 10
        - mode: deterministic
          run_ahead: 10
  # for accelsim simulation, we do not set a limit on concurrency
  accelsim_simulate:
    # No concurrency limit as accelsim is single threaded.
    # Also, it is spawned as a sub process to avoid global state related issues.
    # However, we do not run concurrently to increase accuracy of execution time measurements
    concurrency: 1 # null
    repetitions: 1
    # simulation configurations
    config_dir: ../accelsim/gtx1080/
    config: ../accelsim/gtx1080/gpgpusim.config
    trace_config: ../accelsim/gtx1080/gpgpusim.trace.config
    inter_config: ../accelsim/gtx1080/config_fermi_islip.icnt
  playground_simulate:
    # BUG: due to static global state in intersim2, can only run one benchmark at a time for now
    concurrency: 1
    repetitions: 1
    # simulation configurations
    config_dir: ../accelsim/gtx1080/
    config: ../accelsim/gtx1080/gpgpusim.config
    trace_config: ../accelsim/gtx1080/gpgpusim.trace.config
    inter_config: ../accelsim/gtx1080/config_fermi_islip.icnt
#
# Benchmarks
#
benchmarks:
  vectorAdd:
    path: ./vectoradd
    executable: vectoradd_l1_enabled
    # executable: vectoradd_l1_disabled
    inputs:
      dtype: [32, 64]
      # at a size of 500000 we have 2*500k*4 bytes = 4MB of floats, which is enough to saturate the 2MB L2 cache
      length: [100, 1000, 10000, 20000, 500000]
    args: "{{ input.length }} {{ input.dtype }}"
    simulate:
      traces_dir: "vectorAdd/vectorAdd-dtype-{{ input.dtype }}-length-{{ input.length }}/trace"
      accelsim_traces_dir: "vectorAdd/vectorAdd-dtype-{{ input.dtype }}-length-{{ input.length }}/accelsim-trace"
  simple_matrixmul:
    path: ./simple_matrixmul
    executable: matrixmul
    inputs:
      dtype: [32]
      m: [32, 64, 128]
      n: [32, 64, 128]
      p: [32, 64, 128]
    # (m x n) x (n x p)
    args: "{{ input.m }} {{ input.n }} {{ input.p }} {{ input.dtype }}"
    simulate:
      traces_dir: "simple_matrixmul/simple_matrixmul-dtype-{{ input.dtype }}-m-{{ input.m }}-n-{{ input.n }}-p-{{ input.p }}/trace"
      accelsim_traces_dir: "simple_matrixmul/simple_matrixmul-dtype-{{ input.dtype }}-m-{{ input.m }}-n-{{ input.n }}-p-{{ input.p }}/accelsim-trace"
  matrixmul:
    path: ./matrixmul
    executable: matrixmul
    inputs:
      dtype: [32]
      rows: [32, 64, 128, 256, 512]
      exclude:
        - rows: 512
    # (rows x rows) x (rows x rows)
    args: "{{ input.rows }} {{ input.dtype }}"
    simulate:
      traces_dir: "matrixmul/matrixmul-dtype-{{ input.dtype }}-rows-{{ input.rows }}/trace"
      accelsim_traces_dir: "matrixmul/matrixmul-dtype-{{ input.dtype }}-rows-{{ input.rows }}/accelsim-trace"
  # CUDA 10 transpose (modified to allow running individual implementations)
  transpose:
    path: ./transpose
    executable: transpose
    inputs:
      # must be square matrix
      dim: [256, 512, 1024]
      variant:
        - "naive"
        - "coalesced"
        - "optimized"
      include:
        - repeat: 1
    args: "-variant={{ input.variant }} -dimX={{ input.dim }} -dimY={{ input.dim }} -repeat={{ input.repeat }}"
    simulate:
      traces_dir: "transpose/transpose-dim-{{ input.dim }}-repeat-{{ input.repeat }}-variant-{{ input.variant }}/trace"
      accelsim_traces_dir: "transpose/transpose-dim-{{ input.dim }}-repeat-{{ input.repeat }}-variant-{{ input.variant }}/accelsim-trace"
  babelstream:
    path: ./BabelStream
    executable: CUDAStream
    # - args: --arraysize 1024 --numtimes 1
    # - args: --arraysize 1024 --numtimes 2
    # - args: --arraysize 10240 --numtimes 1
    # - args: --arraysize 102400 --numtimes 1

    inputs:
      size: [1024, 10240, 102400]
    args: "--arraysize {{ input.size }} --numtimes 1"
    exec_driven_simulate:
      enabled: false
    simulate:
      traces_dir: "babelstream/babelstream-size-{{ input.size }}/trace"
      accelsim_traces_dir: "babelstream/babelstream-size-{{ input.size }}/accelsim-trace"
  parboil_bfs:
    path: ./parboil/bfs/src/cuda
    executable: CUDAStream
    # - args: --arraysize 1024 --numtimes 1
    # - args: --arraysize 1024 --numtimes 2
    # - args: --arraysize 10240 --numtimes 1
    # - args: --arraysize 102400 --numtimes 1

    inputs: {}
    # size: [1024, 10240, 102400]
    # args: "--arraysize {{ input.size }} --numtimes 1"
    args: ""
    exec_driven_simulate:
      enabled: false
    # simulate:
    #   traces_dir: "babelstream/babelstream-size-{{ input.size }}/trace"
    #   accelsim_traces_dir: "babelstream/babelstream-size-{{ input.size }}/accelsim-trace"
